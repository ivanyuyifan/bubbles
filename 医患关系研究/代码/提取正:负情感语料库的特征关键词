# ------------------------------------------------------------------
# 任务三：对比性分析 - 提取正面/负面情感语料库的特征关键词
# ------------------------------------------------------------------
# 安装指南:
# 如果尚未安装，请在终端运行: pip install scikit-learn
# ------------------------------------------------------------------

import pandas as pd
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from tqdm import tqdm
import os

# ==============================================================================
# 1. 参数配置区
# ==============================================================================
# 输入文件路径
SENTIMENT_DATA_PATH = '/Users/fafaya/Desktop/医患关系研究/预处理后语料/weibo_data_with_cntext_sentiment.csv'

# 输出特征关键词对比结果的CSV文件路径
OUTPUT_KEYWORDS_PATH = '/Users/fafaya/Desktop/医患关系研究/final_analysis_results/sentiment_keywords_comparison.csv'

# 停用词文件路径
STOPWORDS_PATH = '/Users/fafaya/Desktop/医患关系研究/hit_stopwords.txt'

# 每个情感类别要提取的Top N关键词数量
TOP_N_KEYWORDS = 50

# ==============================================================================
# 2. 主分析函数
# ==============================================================================

def analyze_characteristic_keywords():
    """
    加载数据，创建情感子语料库，并使用TF-IDF提取各自的特征关键词。
    """
    # --- 数据加载与准备 ---
    print("--- 步骤1: 加载带有情感分数的数据 ---")
    try:
        df = pd.read_csv(SENTIMENT_DATA_PATH)
        df.dropna(subset=['微博内容_清洗后', 'net_sentiment_score'], inplace=True)
        print(f"成功加载数据，共 {len(df)} 条记录。\n")
    except FileNotFoundError:
        print(f"错误: 文件未找到，请检查路径 -> {SENTIMENT_DATA_PATH}")
        return

    # --- 创建情感子语料库 ---
    print("--- 步骤2: 创建正面与负面情感子语料库 ---")
    positive_corpus = df[df['net_sentiment_score'] > 0]['微博内容_清洗后'].tolist()
    negative_corpus = df[df['net_sentiment_score'] < 0]['微博内容_清洗后'].tolist()
    print(f"正面情感语料库包含: {len(positive_corpus)} 条微博。")
    print(f"负面情感语料库包含: {len(negative_corpus)} 条微博。\n")
    
    if not positive_corpus or not negative_corpus:
        print("错误: 正面或负面语料库为空，无法进行对比分析。")
        return

    # --- 定义分词与停用词过滤函数 ---
    try:
        with open(STOPWORDS_PATH, 'r', encoding='utf-8') as f:
            stopwords = {line.strip() for line in f}
    except FileNotFoundError:
        print(f"警告: 停用词文件未找到 ({STOPWORDS_PATH})，将不使用停用词过滤。")
        stopwords = set()

    def tokenizer(text):
        """自定义分词器，用于TF-IDF"""
        words = [w for w in jieba.lcut(str(text)) if w.strip() and w not in stopwords and len(w) > 1]
        return words

    # --- 使用TF-IDF提取特征关键词 ---
    print("--- 步骤3: 正在使用TF-IDF提取特征关键词 (此过程可能需要几分钟)... ---")
    
    # 初始化TF-IDF向量化器
    vectorizer = TfidfVectorizer(tokenizer=tokenizer)
    
    # 对正面和负面语料库分别进行TF-IDF分析
    # 注意：这里我们将两个语料库合并起来进行fit_transform，
    # 这样可以确保它们在同一个词汇空间中进行比较，IDF值的计算也更公平。
    all_corpus = [" ".join(tokenizer(doc)) for doc in tqdm(positive_corpus, desc="处理正面语料")] + \
                 [" ".join(tokenizer(doc)) for doc in tqdm(negative_corpus, desc="处理负面语料")]
    
    tfidf_matrix = vectorizer.fit_transform(all_corpus)
    feature_names = vectorizer.get_feature_names_out()
    
    # 分割矩阵，取回正面和负面的部分
    tfidf_positive = tfidf_matrix[:len(positive_corpus)]
    tfidf_negative = tfidf_matrix[len(positive_corpus):]
    
    # 计算每个词在各个类别中的平均TF-IDF值
    mean_tfidf_positive = tfidf_positive.mean(axis=0).A1
    mean_tfidf_negative = tfidf_negative.mean(axis=0).A1
    
    # 创建结果DataFrame
    positive_keywords_df = pd.DataFrame({'keyword': feature_names, 'tfidf_score': mean_tfidf_positive}).sort_values(by='tfidf_score', ascending=False).head(TOP_N_KEYWORDS)
    negative_keywords_df = pd.DataFrame({'keyword': feature_names, 'tfidf_score': mean_tfidf_negative}).sort_values(by='tfidf_score', ascending=False).head(TOP_N_KEYWORDS)
    
    # 合并成一个对比表格
    comparison_df = pd.DataFrame({
        'Rank': range(1, TOP_N_KEYWORDS + 1),
        'Positive_Keywords': positive_keywords_df['keyword'].values,
        'Positive_TFIDF': positive_keywords_df['tfidf_score'].values,
        'Negative_Keywords': negative_keywords_df['keyword'].values,
        'Negative_TFIDF': negative_keywords_df['tfidf_score'].values
    })
    
    print("关键词提取完毕！\n")

    # --- 保存结果 ---
    print("--- 步骤4: 保存结果 ---")
    # 确保输出目录存在
    output_dir = os.path.dirname(OUTPUT_KEYWORDS_PATH)
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    comparison_df.to_csv(OUTPUT_KEYWORDS_PATH, index=False, encoding='utf-8-sig')
    print(f"成功！特征关键词对比结果已保存至:\n{OUTPUT_KEYWORDS_PATH}\n")
    
    # 在控制台打印结果，方便快速预览
    print("--- 特征关键词对比预览 ---")
    print(comparison_df)

if __name__ == '__main__':
    analyze_characteristic_keywords()
